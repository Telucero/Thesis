{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import glob\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import academictorrents as at\n",
    "import tarfile\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations and load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = datasets.MNIST('mnist_data/', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('mnist_data/', train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "dataset = datasets.MNIST('mnist_data/', train=True, download=True, transform=transform)\n",
    "\n",
    "# Split the dataset into training, validation, and testing sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create data loaders for each set\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.3085:   0%|          | 1/750 [00:00<02:22,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1722: 100%|██████████| 750/750 [01:40<00:00,  7.43it/s]\n",
      "Train Loss: 0.0938:   0%|          | 1/750 [00:00<01:43,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0680, Validation Accuracy: 97.93%\n",
      "Epoch 2/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0653: 100%|██████████| 750/750 [01:41<00:00,  7.41it/s]\n",
      "Train Loss: 0.0345:   0%|          | 1/750 [00:00<01:41,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0543, Validation Accuracy: 98.45%\n",
      "Epoch 3/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0464: 100%|██████████| 750/750 [01:43<00:00,  7.26it/s]\n",
      "Train Loss: 0.0113:   0%|          | 1/750 [00:00<01:45,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0471, Validation Accuracy: 98.57%\n",
      "Epoch 4/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0350: 100%|██████████| 750/750 [01:43<00:00,  7.22it/s]\n",
      "Train Loss: 0.0165:   0%|          | 1/750 [00:00<01:45,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0498, Validation Accuracy: 98.52%\n",
      "Epoch 5/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0278: 100%|██████████| 750/750 [01:37<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0409, Validation Accuracy: 98.82%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the CNN model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(64 * 12 * 12, 128)  # Adjust the input size for the fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "# Define the training function\n",
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    pbar = tqdm(train_loader)\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        pbar.set_description(f'Train Loss: {train_loss / (batch_idx + 1):.4f}')\n",
    "\n",
    "# Define the testing/evaluation function\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += nn.functional.nll_loss(output, target, reduction='sum').item()  # Change val_loss to test_loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loader.dataset)  # Change val_loss to test_loss\n",
    "    accuracy = 100. * correct / len(loader.dataset)\n",
    "    return test_loss, accuracy\n",
    "\n",
    "\n",
    "# Set device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create an instance of the model and move it to the device\n",
    "model = Net().to(device)\n",
    "\n",
    "# Define optimizer, loss function, and learning rate scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{num_epochs}:\")\n",
    "    train(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, accuracy = test(model, val_loader, device)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5924\n",
      "Test Loss: 0.0411, Test Accuracy: 98.73%\n"
     ]
    }
   ],
   "source": [
    "# Create the test loader\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += nn.functional.nll_loss(output, target, reduction='sum').item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "accuracy = 100. * correct / len(test_loader.dataset)\n",
    "print(correct)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Iterate over the test loader and print the shape of the data\n",
    "for data, _ in test_loader:\n",
    "    print(data.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "108864\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[108864, 1, 28, 28]' is invalid for input of size 217728",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-80b886c7b445>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# Call the function to visualize the decision boundaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mplot_decision_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-68-80b886c7b445>\u001b[0m in \u001b[0;36mplot_decision_boundaries\u001b[0;34m(model, device, test_loader, labels)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mnum_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mgrid_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Get the predicted class probabilities for the grid points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[108864, 1, 28, 28]' is invalid for input of size 217728"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_decision_boundaries(model, device, test_loader, labels):\n",
    "    # Extract the input shape from the test loader\n",
    "    input_shape = next(iter(test_loader))[0].shape[1:]\n",
    "    print(input_shape)\n",
    "\n",
    "    # Get the range of values for each feature dimension in the dataset\n",
    "    x_min, x_max = 0, 27\n",
    "    y_min, y_max = 0, 27\n",
    "\n",
    "    # Add some padding to the range to ensure all points are included in the plot\n",
    "    x_padding = 0.1 * (x_max - x_min)\n",
    "    y_padding = 0.1 * (y_max - y_min)\n",
    "    x_min -= x_padding\n",
    "    x_max += x_padding\n",
    "    y_min -= y_padding\n",
    "    y_max += y_padding\n",
    "\n",
    "    step = 0.1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, step), np.arange(y_min, y_max, step))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    print(len(grid))\n",
    "\n",
    "    # Move the grid to the device\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).to(device)\n",
    "    num_points = grid_tensor.size(0)\n",
    "    \n",
    "    grid_tensor = grid_tensor.view(num_points, 1, input_shape[1], input_shape[2])\n",
    "    # Get the predicted class probabilities for the grid points\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(grid_tensor)\n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "        _, predicted_classes = torch.max(probabilities, 1)\n",
    "        predicted_classes = predicted_classes.cpu().numpy()\n",
    "\n",
    "    # Reshape the predicted classes into the grid shape\n",
    "    decision_boundary = predicted_classes.reshape(xx.shape)\n",
    "\n",
    "    # Plot the decision boundaries\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.contourf(xx, yy, decision_boundary, alpha=0.8, cmap=plt.cm.Paired)\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.title('Decision Boundaries')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Assuming you have the labels for your classification problem\n",
    "labels_list = [x for x in range(10)]  # Adjust the range based on the number of classes\n",
    "\n",
    "# Assuming you have trained your model and stored it in the 'model' variable\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Move the model to the desired device\n",
    "model.to(device)\n",
    "\n",
    "# Create a test dataloader without specifying the batch size\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False)\n",
    "\n",
    "# Call the function to visualize the decision boundaries\n",
    "plot_decision_boundaries(model, device, test_loader, labels_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def plot_decision_boundaries(model, device, test_loader):\n",
    "    # Extract the input shape from the test loader\n",
    "    input_shape = next(iter(test_loader))[0].shape[1:]\n",
    "    \n",
    "    # Access the original dataset from the Subset object\n",
    "    original_dataset = test_loader.dataset.dataset\n",
    "    \n",
    "    # Get the data from the original dataset\n",
    "    data = original_dataset.data\n",
    "    \n",
    "    # Apply PCA to reduce the dimensionality of the input space\n",
    "    pca = PCA(n_components=2)  # Set the desired number of components\n",
    "    pca.fit(data.view(-1, input_shape[0] * input_shape[1] * input_shape[2]).numpy())\n",
    "    reduced_data = pca.transform(data.view(-1, input_shape[0] * input_shape[1] * input_shape[2]).numpy())\n",
    "    \n",
    "    # Get the range of values for each feature dimension in the reduced space\n",
    "    x_min, x_max = reduced_data[:, 0].min(), reduced_data[:, 0].max()\n",
    "    y_min, y_max = reduced_data[:, 1].min(), reduced_data[:, 1].max()\n",
    "\n",
    "    # Add some padding to the range to ensure all points are included in the plot\n",
    "    x_padding = 0.1 * (x_max - x_min)\n",
    "    y_padding = 0.1 * (y_max - y_min)\n",
    "    x_min -= x_padding\n",
    "    x_max += x_padding\n",
    "    y_min -= y_padding\n",
    "    y_max += y_padding\n",
    "\n",
    "    step = 0.1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, step), np.arange(y_min, y_max, step))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    \n",
    "    # Convert the grid to a tensor and move it to the device\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Get the predicted class probabilities for the grid points\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(grid_tensor)\n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "        _, predicted_classes = torch.max(probabilities, 1)\n",
    "        predicted_classes = predicted_classes.cpu().numpy()\n",
    "    \n",
    "    # Reshape the predicted classes into the grid shape\n",
    "    decision_boundary = predicted_classes.reshape(xx.shape)\n",
    "    \n",
    "    # Plot the decision boundaries\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.contourf(xx, yy, decision_boundary, alpha=0.8, cmap=plt.cm.Paired)\n",
    "    plt.xlabel('PC 1')\n",
    "    plt.ylabel('PC 2')\n",
    "    plt.title('Decision Boundaries')\n",
    "    plt.show()\n",
    "\n",
    "plot_decision_boundaries(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
